{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2Vyn5JOWj4AlauXUgoFSX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiveAdityaSingh/ML-Projects/blob/main/ClothswapGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHnXoSIGpUXi"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.activations import relu\n",
        "from keras.initializers import RandomNormal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmc1_fWVjWWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec234b96-b682-498f-8432-bcba113b67f1"
      },
      "source": [
        "!git clone https://github.com/LiveAdityaSingh/CAGAN.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CAGAN' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-nSOSIzsyO2"
      },
      "source": [
        "from CAGAN.instance_normalization import InstanceNormalization\n",
        "#from CAGAN.Instance_normalization import InstanceNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weSPxfE-pcM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc993af-2080-46cf-ed15-fce6fa3d8ce0"
      },
      "source": [
        "from keras.applications import *\n",
        "import tensorflow as tf\n",
        "!pip install --upgrade tensorflow==2.2\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import glob\n",
        "from random import randint, shuffle\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow==2.2 in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (2.2.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (54.0.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.27.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.7.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSA9giZZpefP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d45ad19-db11-4826-ccbb-92cdb75824df"
      },
      "source": [
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  if previous_graph_value is not None:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYSbGPkuph2t"
      },
      "source": [
        "channel_axis=-1\n",
        "channel_first = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqGGPdRYpkFE"
      },
      "source": [
        "nc_in = 9\n",
        "nc_out = 4\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "use_lsgan = False\n",
        "use_nsgan = False # non-saturating GAN\n",
        "λ = 10 if use_lsgan else 100\n",
        "\n",
        "# ========== CAGAN config ==========\n",
        "nc_G_inp = 9 # [x_im y_im y_j]\n",
        "nc_G_out = 4 # [alpha, x_i_j(RGB)]\n",
        "nc_D_inp = 6 # Pos: [x_i, y_i]; Neg1: [G_out(x_i), y_i]; Neg2: [x_i, y_j]\n",
        "nc_D_out = 1\n",
        "gamma_i = 0.1\n",
        "use_instancenorm = True\n",
        "\n",
        "loadSize = 143\n",
        "imageSize = 128\n",
        "batchSize = 16 #1\n",
        "lrD = 2e-4\n",
        "lrG = 2e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bIEmpEOpnOl"
      },
      "source": [
        "# Weights initializations\n",
        "# bias are initailized as 0\n",
        "def __conv_init(a):\n",
        "    print(\"conv_init\", a)\n",
        "    k = RandomNormal(0, 0.02)(a) # for convolution kernel\n",
        "    k.conv_weight = True\n",
        "    return k\n",
        "conv_init = RandomNormal(0, 0.02)\n",
        "gamma_init = RandomNormal(1., 0.02) # for batch normalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMZKQ9oGpq2X"
      },
      "source": [
        "def conv2d(f, *a, **k):\n",
        "    return Conv2D(f, kernel_initializer = conv_init, *a, **k)\n",
        "\n",
        "def batchnorm():\n",
        "    return BatchNormalization(momentum=0.9, axis=channel_axis, epsilon=1.01e-5,\n",
        "                                   gamma_initializer = gamma_init)\n",
        "\n",
        "def instance_norm():\n",
        "    return InstanceNormalization(axis=channel_axis, epsilon=1.01e-5,\n",
        "                                   gamma_initializer = gamma_init)\n",
        "\n",
        "def BASIC_D(nc_in, ndf, max_layers=3, use_sigmoid=True):\n",
        "    \"\"\"\n",
        "    DCGAN_D(nc, ndf, max_layers=3)\n",
        "    nc: channels\n",
        "    ndf: filters of the first layer\n",
        "    max_layers: max hidden layers\n",
        "    \"\"\"\n",
        "    if channel_first:\n",
        "        input_a =  Input(shape=(nc_in, None, None))\n",
        "    else:\n",
        "        input_a = Input(shape=(None, None, nc_in))\n",
        "    _ = input_a\n",
        "    _ = conv2d(ndf, kernel_size=4, strides=2, padding=\"same\", name = 'First') (_)\n",
        "    _ = LeakyReLU(alpha=0.2)(_)\n",
        "\n",
        "    for layer in range(1, max_layers):\n",
        "        out_feat = ndf * min(2**layer, 8)\n",
        "        _ = conv2d(out_feat, kernel_size=4, strides=2, padding=\"same\",\n",
        "                   use_bias=False, name = 'pyramid.{0}'.format(layer)\n",
        "                        ) (_)\n",
        "        _ = batchnorm()(_, training=1)\n",
        "        _ = LeakyReLU(alpha=0.2)(_)\n",
        "\n",
        "    out_feat = ndf*min(2**max_layers, 8)\n",
        "    _ = ZeroPadding2D(1)(_)\n",
        "    _ = conv2d(out_feat, kernel_size=4,  use_bias=False, name = 'pyramid_last') (_)\n",
        "    _ = batchnorm()(_, training=1)\n",
        "    _ = LeakyReLU(alpha=0.2)(_)\n",
        "\n",
        "    # final layer\n",
        "    _ = ZeroPadding2D(1)(_)\n",
        "    _ = conv2d(1, kernel_size=4, name = 'final'.format(out_feat, 1),\n",
        "               activation = \"sigmoid\" if use_sigmoid else None) (_)\n",
        "    return Model(inputs=[input_a], outputs=_)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    UNet gives slightly better results than Resnet in some of the pix2pix applications.\n",
        "    We haven't varied the depth of the UNet model, but it might be worth trying.\n",
        "\"\"\"\n",
        "def UNET_G(isize, nc_in=3, nc_out=3, ngf=64, fixed_input_size=True, use_batchnorm=True):\n",
        "\n",
        "    s = isize if fixed_input_size else None\n",
        "    _ = inputs = Input(shape=(s, int(s*.75), nc_in))\n",
        "    x_i = Lambda(lambda x: x[:, :, :, 0:3], name='x_i')(inputs)\n",
        "    y_i = Lambda(lambda x: x[:, :, :, 3:6], name='y_j')(inputs)\n",
        "    xi_and_y_i = concatenate([x_i, y_i], name = 'xi_yi')\n",
        "    xi_yi_sz64 = AveragePooling2D(pool_size=2)(xi_and_y_i)\n",
        "    xi_yi_sz32 = AveragePooling2D(pool_size=4)(xi_and_y_i)\n",
        "    xi_yi_sz16 = AveragePooling2D(pool_size=8)(xi_and_y_i)\n",
        "    xi_yi_sz8 = AveragePooling2D(pool_size=16)(xi_and_y_i)\n",
        "    layer1 = conv2d(64, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
        "                   padding=\"same\", name = 'layer1') (_)\n",
        "    layer1 = LeakyReLU(alpha=0.2)(layer1)\n",
        "    layer1 = concatenate([layer1, xi_yi_sz64]) # ==========\n",
        "    layer2 = conv2d(128, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
        "                   padding=\"same\", name = 'layer2') (layer1)\n",
        "    if use_instancenorm:\n",
        "        layer2 = instance_norm()(layer2, training=1)\n",
        "    else:\n",
        "        layer2 = batchnorm()(layer2, training=1)\n",
        "    layer3 = LeakyReLU(alpha=0.2)(layer2)\n",
        "    layer3 = concatenate([layer3, xi_yi_sz32]) # ==========\n",
        "    layer3 = conv2d(256, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
        "                   padding=\"same\", name = 'layer3') (layer3)\n",
        "    if use_instancenorm:\n",
        "        layer3 = instance_norm()(layer3, training=1)\n",
        "    else:\n",
        "        layer3 = batchnorm()(layer3, training=1)\n",
        "    layer4 = LeakyReLU(alpha=0.2)(layer3)\n",
        "    layer4 = concatenate([layer4, xi_yi_sz16]) # ==========\n",
        "    layer4 = conv2d(512, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
        "                   padding=\"same\", name = 'layer4') (layer4)\n",
        "    if use_instancenorm:\n",
        "        layer4 = instance_norm()(layer4, training=1)\n",
        "    else:\n",
        "        layer4 = batchnorm()(layer4, training=1)\n",
        "    layer4 = LeakyReLU(alpha=0.2)(layer4)\n",
        "    layer4 = concatenate([layer4, xi_yi_sz8]) # ==========\n",
        "\n",
        "    layer9 = Conv2DTranspose(256, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
        "                            kernel_initializer = conv_init, name = 'layer9')(layer4)\n",
        "    layer9 = Cropping2D(((1,1),(1,1)))(layer9)\n",
        "    if use_instancenorm:\n",
        "        layer9 = instance_norm()(layer9, training=1)\n",
        "    else:\n",
        "        layer9 = batchnorm()(layer9, training=1)\n",
        "    layer9 = Concatenate(axis=channel_axis)([layer9, layer3])\n",
        "    layer9 = Activation('relu')(layer9)\n",
        "    layer9 = concatenate([layer9, xi_yi_sz16]) # ==========\n",
        "    layer10 = Conv2DTranspose(128, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
        "                            kernel_initializer = conv_init, name = 'layer10')(layer9)\n",
        "    layer10 = Cropping2D(((1,1),(1,1)))(layer10)\n",
        "    if use_instancenorm:\n",
        "        layer10 = instance_norm()(layer10, training=1)\n",
        "    else:\n",
        "        layer10 = batchnorm()(layer10, training=1)\n",
        "    layer10 = Concatenate(axis=channel_axis)([layer10, layer2])\n",
        "    layer10 = Activation('relu')(layer10)\n",
        "    layer10 = concatenate([layer10, xi_yi_sz32]) # ==========\n",
        "    layer11 = Conv2DTranspose(64, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
        "                            kernel_initializer = conv_init, name = 'layer11')(layer10)\n",
        "    layer11 = Cropping2D(((1,1),(1,1)))(layer11)\n",
        "    if use_instancenorm:\n",
        "        layer11 = instance_norm()(layer11, training=1)\n",
        "    else:\n",
        "        layer11 = batchnorm()(layer11, training=1)\n",
        "    layer11 = Activation('relu')(layer11)\n",
        "\n",
        "    layer12 = concatenate([layer11, xi_yi_sz64]) # ==========\n",
        "    layer12 = Activation('relu')(layer12)\n",
        "    layer12 = Conv2DTranspose(32, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
        "                            kernel_initializer = conv_init, name = 'layer12')(layer12)\n",
        "    layer12 = Cropping2D(((1,1),(1,1)))(layer12)\n",
        "    if use_instancenorm:\n",
        "        layer12 = instance_norm()(layer12, training=1)\n",
        "    else:\n",
        "        layer12 = batchnorm()(layer12, training=1)\n",
        "\n",
        "    layer12 = conv2d(4, kernel_size=4, strides=1, use_bias=(not (use_batchnorm and s>2)),\n",
        "                   padding=\"same\", name = 'out128') (layer12)\n",
        "\n",
        "    alpha = Lambda(lambda x: x[:, :, :, 0:1], name='alpha')(layer12)\n",
        "    x_i_j = Lambda(lambda x: x[:, :, :, 1:], name='x_i_j')(layer12)\n",
        "    alpha = Activation(\"sigmoid\", name='alpha_sigmoid')(alpha)\n",
        "    x_i_j = Activation(\"tanh\", name='x_i_j_tanh')(x_i_j)\n",
        "    out = concatenate([alpha, x_i_j], name = 'out128_concat')\n",
        "\n",
        "    return Model(inputs=inputs, outputs=[out])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zg9CqSqp0Zn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "82b87f80-7450-4ccf-deef-f8235df133d7"
      },
      "source": [
        "netGA = UNET_G(imageSize, nc_G_inp, nc_G_out, ngf)\n",
        "#netGA.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ad3b51ffdc37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetGA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNET_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc_G_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc_G_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#netGA.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-a50f0595dc75>\u001b[0m in \u001b[0;36mUNET_G\u001b[0;34m(isize, nc_in, nc_out, ngf, fixed_input_size, use_batchnorm)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misize\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfixed_input_size\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x_i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0my_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y_j'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/version_utils.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv2_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meager_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautocast_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/experimental/autocast_variable.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m ops.register_tensor_conversion_function(AutoCastVariable,\n\u001b[1;32m    419\u001b[0m                                         AutoCastVariable._dense_var_to_tensor)  # pylint:disable=protected-access\n\u001b[0;32m--> 420\u001b[0;31m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_dense_tensor_like_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoCastVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.framework.ops' has no attribute 'register_dense_tensor_like_type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiynSvACp4aq"
      },
      "source": [
        "netDA = BASIC_D(nc_D_inp, ndf, use_sigmoid = not use_lsgan)\n",
        "#netDA.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQsUC6Eip7nC"
      },
      "source": [
        "def cycle_variables(netG1):\n",
        "    \"\"\"\n",
        "    Intermidiate params:\n",
        "        x_i: human w/ cloth i, shape=(128,96,3)\n",
        "        y_i: stand alone cloth i, shape=(128,96,3)\n",
        "        y_j: stand alone cloth j, shape=(128,96,3)\n",
        "        alpha: mask for x_i_j, shape=(128,96,1)\n",
        "        x_i_j: generated fake human swapping cloth i to j, shape=(128,96,3)\n",
        "\n",
        "    Out:\n",
        "        real_input: concat[x_i, y_i, y_j], shape=(128,96,9)\n",
        "        fake_output: masked_x_i_j = alpha*x_i_j + (1-alpha)*x_i, shape=(128,96,3)\n",
        "        rec_input: output of the second generator (generating image similar to x_i), shape=(128,96,3)\n",
        "        fn_generate: a path from input to G_out and cyclic G_out\n",
        "    \"\"\"\n",
        "    real_input = netG1.inputs[0]\n",
        "    fake_output = netG1.outputs[0]\n",
        "    # Legacy: how to split channels\n",
        "    # https://github.com/fchollet/keras/issues/5474\n",
        "    x_i = Lambda(lambda x: x[:,:,:, 0:3])(real_input)\n",
        "    y_i = Lambda(lambda x: x[:,:,:, 3:6])(real_input)\n",
        "    y_j = Lambda(lambda x: x[:,:,:, 6:])(real_input)\n",
        "    alpha = Lambda(lambda x: x[:,:,:, 0:1])(fake_output)\n",
        "    x_i_j = Lambda(lambda x: x[:,:,:, 1:])(fake_output)\n",
        "\n",
        "    fake_output = alpha*x_i_j + (1-alpha)*x_i\n",
        "    concat_input_G2 = concatenate([fake_output, y_j, y_i], axis=-1) # swap y_i and y_j\n",
        "    rec_input = netG1([concat_input_G2])\n",
        "    rec_alpha = Lambda(lambda x: x[:,:,:, 0:1])(rec_input)\n",
        "    rec_x_i_j = Lambda(lambda x: x[:,:,:, 1:])(rec_input)\n",
        "    rec_input = rec_alpha*rec_x_i_j + (1-rec_alpha)*fake_output\n",
        "    fn_generate = K.function([real_input], [fake_output, rec_input])\n",
        "    return real_input, fake_output, rec_input, fn_generate, alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw-y9WBOp_FL"
      },
      "source": [
        "\n",
        "real_A, fake_B, rec_A, cycleA_generate, alpha_A = cycle_variables(netGA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2C4ZUdkqB1w"
      },
      "source": [
        "if use_lsgan:\n",
        "    loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n",
        "else:\n",
        "    loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YavR87J6qEeb"
      },
      "source": [
        "def D_loss(netD, real, fake, rec):\n",
        "    #x_i, y_i, y_j = tf.split(real, [3, 3, 3], 3)\n",
        "    x_i = Lambda(lambda x: x[:,:,:, 0:3])(real)\n",
        "    y_i = Lambda(lambda x: x[:,:,:, 3:6])(real)\n",
        "    y_j = Lambda(lambda x: x[:,:,:, 6:])(real)\n",
        "    x_i_j = fake\n",
        "\n",
        "    output_real = netD(concatenate([x_i, y_i])) # positive sample\n",
        "    output_fake = netD(concatenate([x_i_j, y_j])) # negative sample\n",
        "    output_fake2 = netD(concatenate([x_i, y_j])) # negative sample 2\n",
        "\n",
        "    loss_D_real = loss_fn(output_real, K.ones_like(output_real))\n",
        "    loss_D_fake = loss_fn(output_fake, K.zeros_like(output_fake))\n",
        "    loss_D_fake2 = loss_fn(output_fake2, K.zeros_like(output_fake2)) # New loss term for discriminator\n",
        "    if not use_nsgan:\n",
        "        loss_G = loss_fn(output_fake, K.ones_like(output_fake))\n",
        "    else:\n",
        "        loss_G = K.mean(K.log(output_fake))\n",
        "\n",
        "    loss_D = loss_D_real+(loss_D_fake+loss_D_fake2)\n",
        "    loss_cyc = K.mean(K.abs(rec-x_i)) # cycle loss\n",
        "    return loss_D, loss_G, loss_cyc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXXWvlivqHh5"
      },
      "source": [
        "loss_DA, loss_GA, loss_cycA = D_loss(netDA, real_A, fake_B, rec_A)\n",
        "loss_cyc = loss_cycA\n",
        "loss_id = K.mean(K.abs(alpha_A)) # loss of alpha\n",
        "\n",
        "loss_G = loss_GA + 1*(1*loss_cyc + gamma_i*loss_id)\n",
        "loss_D = loss_DA*2\n",
        "\n",
        "weightsD = netDA.trainable_weights\n",
        "weightsG = netGA.trainable_weights\n",
        "\n",
        "training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(params=weightsD,loss=loss_D)\n",
        "netD_train = K.function([real_A],[loss_DA/2], training_updates)\n",
        "training_updates = Adam(lr=lrG, beta_1=0.5).get_updates(params=weightsG, loss=loss_G)\n",
        "netG_train = K.function([real_A], [loss_GA, loss_cyc], training_updates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gF_e3YwqR9c"
      },
      "source": [
        "Load Image¶\n",
        "Filenames:\n",
        "\n",
        "\"./imgs/1/fileID_1.jpg\" for human images.\n",
        "\"./imgs/5/fileID_5.jpg\" for article images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVeiLjpDqK3u"
      },
      "source": [
        "\n",
        "isRGB = True\n",
        "apply_da = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2p2o-2XqO8z"
      },
      "source": [
        "def load_data(file_pattern):\n",
        "    return glob.glob(file_pattern)\n",
        "\n",
        "def crop_img(img, large_size, small_size):\n",
        "    # only apply DA to human images\n",
        "    img_width = small_size[0]\n",
        "    img_height = small_size[1]\n",
        "    diff_size = (large_size[0]-small_size[0], large_size[1]-small_size[1])\n",
        "\n",
        "    x_range = [i for i in range(diff_size[0])]\n",
        "    y_range = [j for j in range(diff_size[1])]\n",
        "    x0 = np.random.choice(x_range)\n",
        "    y0 = np.random.choice(y_range)\n",
        "\n",
        "    img = np.array(img)\n",
        "\n",
        "    img = img[y0: y0+img_height, x0: x0+img_width, :]\n",
        "\n",
        "    return img\n",
        "\n",
        "def read_image(fn):\n",
        "    input_size = (111,148)\n",
        "    cropped_size = (96,128)\n",
        "\n",
        "    if isRGB:\n",
        "    # Load human picture\n",
        "        im = Image.open(fn).convert('RGB')\n",
        "        im = im.resize( input_size, Image.BILINEAR )\n",
        "    else:\n",
        "        im = cv2.imread(fn)\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
        "        im = cv2.resize(im, input_size, interpolation=cv2.INTER_CUBIC)\n",
        "    if apply_da is True:\n",
        "        im = crop_img(im, input_size, cropped_size)\n",
        "    arr = np.array(im)/255*2-1\n",
        "    img_x_i = arr\n",
        "    if channel_first:\n",
        "        img_x_i = np.moveaxis(img_x_i, 2, 0)\n",
        "\n",
        "    # Load article picture y_i\n",
        "    fn_y_i = fn[:-5] + \"5.jpg\"\n",
        "    fn_y_i = fn_y_i[:fn_y_i.rfind(\"/\")-1] + \"5/\" + fn_y_i.split(\"/\")[-1]\n",
        "    if isRGB:\n",
        "        im = Image.open(fn_y_i).convert('RGB')\n",
        "        im = im.resize(cropped_size, Image.BILINEAR )\n",
        "    else:\n",
        "        im = cv2.imread(fn_y_i)\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
        "        im = cv2.resize(im, cropped_size, interpolation=cv2.INTER_CUBIC)\n",
        "    arr = np.array(im)/255*2-1\n",
        "    img_y_i = arr\n",
        "    if channel_first:\n",
        "        img_y_i = np.moveaxis(img_y_i, 2, 0)\n",
        "\n",
        "    # Load article picture y_j randomly\n",
        "    fn_y_j = np.random.choice(filenames_5)\n",
        "    while (fn_y_j == fn_y_i):\n",
        "        fn_y_j = np.random.choice(filenames_5)\n",
        "    if isRGB:\n",
        "        im = Image.open(fn_y_j).convert('RGB')\n",
        "        im = im.resize( cropped_size, Image.BILINEAR )\n",
        "    else:\n",
        "        im = cv2.imread(fn_y_j)\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
        "        im = cv2.resize(im, cropped_size, interpolation=cv2.INTER_CUBIC)\n",
        "    arr = np.array(im)/255*2-1\n",
        "    img_y_j = arr\n",
        "    if randint(0,1):\n",
        "        img_y_j=img_y_j[:,::-1]\n",
        "    if channel_first:\n",
        "        img_y_j = np.moveaxis(img_y_j, 2, 0)\n",
        "\n",
        "    if randint(0,1): # prevent disalign of the graphic on t-shirts and human when fplipping\n",
        "        img_x_i=img_x_i[:,::-1]\n",
        "        img_y_i=img_y_i[:,::-1]\n",
        "\n",
        "    img = np.concatenate([img_x_i, img_y_i, img_y_j], axis=-1)\n",
        "    assert img.shape[-1] == 9\n",
        "\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODPs_9msqZyL"
      },
      "source": [
        "data = \"imgs\"\n",
        "train_A = load_data('./{}/1/*.jpg'.format(data))\n",
        "\n",
        "filenames_1 = load_data('./{}/1/*.jpg'.format(data))\n",
        "filenames_5 = load_data('./{}/5/*.jpg'.format(data))\n",
        "\n",
        "assert len(train_A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDd84YDzqdL8"
      },
      "source": [
        "def minibatch(data, batchsize):\n",
        "    length = len(data)\n",
        "    epoch = i = 0\n",
        "    tmpsize = None\n",
        "    while True:\n",
        "        size = tmpsize if tmpsize else batchsize\n",
        "        if i+size > length:\n",
        "            shuffle(data)\n",
        "            i = 0\n",
        "            epoch+=1\n",
        "        rtn = [read_image(data[j]) for j in range(i,i+size)]\n",
        "        i+=size\n",
        "        tmpsize = yield epoch, np.float32(rtn)\n",
        "\n",
        "def minibatchAB(dataA, batchsize):\n",
        "    batchA=minibatch(dataA, batchsize)\n",
        "    tmpsize = None\n",
        "    while True:\n",
        "        ep1, A = batchA.send(tmpsize)\n",
        "        tmpsize = yield ep1, A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LQhpGWPqgQ5"
      },
      "source": [
        "from IPython.display import display\n",
        "def showX(X, rows=1):\n",
        "    assert X.shape[0]%rows == 0\n",
        "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
        "    #print (int_X.shape)\n",
        "    if channel_first:\n",
        "        int_X = np.moveaxis(int_X.reshape(-1,3,128,96), 1, 3)\n",
        "    else:\n",
        "        if X.shape[-1] == 9:\n",
        "            img_x_i = int_X[:,:,:,:3]\n",
        "            img_y_i = int_X[:,:,:,3:6]\n",
        "            img_y_j = int_X[:,:,:,6:9]\n",
        "            int_X = np.concatenate([img_x_i, img_y_i, img_y_j], axis=1)\n",
        "        else:\n",
        "            int_X = int_X.reshape(-1,128,96, 3)\n",
        "    int_X = int_X.reshape(rows, -1, 128, 96,3).swapaxes(1,2).reshape(rows*imageSize,-1, 3)\n",
        "    if not isRGB:\n",
        "        int_X = cv2.cvtColor(int_X, cv2.COLOR_LAB2RGB)\n",
        "    display(Image.fromarray(int_X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aHEpXMUqi-p"
      },
      "source": [
        "def showG(A):\n",
        "    def G(fn_generate, X):\n",
        "        r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
        "        return r.swapaxes(0,1)[:,:,0]\n",
        "    rA = G(cycleA_generate, A)\n",
        "    arr = np.concatenate([A[:,:,:,:3], A[:,:,:,3:6], A[:,:,:,6:9], rA[0], rA[1]])\n",
        "    showX(arr,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNqhV7D7qlYl"
      },
      "source": [
        "t0 = time.time()\n",
        "niter = 150\n",
        "gen_iterations = 0\n",
        "epoch = 0\n",
        "errCyc_sum = errGA_sum = errDA_sum = errC_sum = 0\n",
        "\n",
        "display_iters = 15\n",
        "train_batch = minibatchAB(train_A, batchSize)\n",
        "\n",
        "#while epoch < niter:\n",
        "while gen_iterations < 5000:\n",
        "    print(\"Iterations Begin\")\n",
        "    epoch, A = next(train_batch)\n",
        "    errDA  = netD_train([A])\n",
        "    errDA_sum +=errDA[0]\n",
        "\n",
        "    # epoch, trainA, trainB = next(train_batch)\n",
        "    errGA, errCyc = netG_train([A])\n",
        "    errGA_sum += errGA\n",
        "    errCyc_sum += errCyc\n",
        "    gen_iterations+=1\n",
        "    if gen_iterations%display_iters==0:\n",
        "        if gen_iterations%(10*display_iters)==0: # clear_output every 500 iters\n",
        "            clear_output()\n",
        "        print('[%d/%d][%d] Loss_D: %f Loss_G: %f loss_cyc: %f'\n",
        "        % (epoch, niter, gen_iterations, errDA_sum/display_iters,\n",
        "           errGA_sum/display_iters, errCyc_sum/display_iters), time.time()-t0)\n",
        "        _, A = train_batch.send(4)\n",
        "        showG(A)\n",
        "        errCyc_sum = errGA_sum = errDA_sum = errC_sum = 0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}